import os
import io
from textwrap import wrap
import streamlit as st
import pandas as pd
from datetime import datetime
from fpdf import FPDF
from langchain.schema import HumanMessage, AIMessage
from backend import build_or_load_index, query_faiss_index, get_llm_response

# Optional imports
try:
    import docx
except ImportError:
    docx = None
try:
    import pptx
except ImportError:
    pptx = None

# â€”â€”â€” Simple PDF class â€”â€”â€”
class SimplePDF(FPDF):
    def header(self):
        self.set_font("Arial", "B", 16)
        self.cell(0, 10, "Chat Conversation Report", ln=True, align="C")
        self.set_font("Arial", "", 10)
        self.cell(0, 8, datetime.now().strftime("%B %d, %Y %H:%M"), ln=True, align="C")
        self.ln(5)

    def footer(self):
        self.set_y(-15)
        self.set_font("Arial", "I", 8)
        self.cell(0, 10, f"Page {self.page_no()}", align="C")

def make_pdf_bytes(chat_history):
    pdf = SimplePDF()
    pdf.set_auto_page_break(True, margin=15)
    pdf.add_page()
    pdf.set_font("Arial", "", 12)

    # For each message, print Role + wrapped text
    for msg in chat_history:
        role = "User" if isinstance(msg, HumanMessage) else "Assistant"
        text = msg.content.strip().replace("\n", " ")
        # Header
        pdf.set_font("Arial", "B", 12)
        pdf.cell(0, 8, f"{role}:", ln=True)
        # Body
        pdf.set_font("Arial", "", 12)
        # Wrap at ~90 characters
        for line in wrap(text, width=90):
            pdf.cell(5)  # small indent
            pdf.cell(0, 8, line, ln=True)
        pdf.ln(2)

    raw = pdf.output(dest="S")
    return bytes(raw) if isinstance(raw, bytearray) else raw.encode("latin-1")


# â€”â€”â€” Streamlit UI â€”â€”â€”
st.set_page_config(page_title="ğŸ“˜ Document Chat Agent", layout="wide")
try:
    GROQ_API_KEY = st.secrets["GROQ"]["API_KEY"]
except KeyError:
    st.error("ğŸš« Add your GROQ API key under [GROQ] API_KEY in secrets.")
    st.stop()

st.sidebar.markdown("## âš™ï¸ Settings")
uploaded_file = st.sidebar.file_uploader(
    "Upload document (PDF, TXT, DOCX, PPTX, CSV)",
    type=["pdf", "txt", "docx", "pptx", "csv"]
)
show_context = st.sidebar.checkbox("ğŸ” Show Retrieved Contexts")
if st.sidebar.button("ğŸ§¹ Clear Conversation"):
    st.session_state.pop("chat_history", None)

st.markdown("<h1 style='text-align:center;'>ğŸ’¬ Document Chat Agent</h1>", unsafe_allow_html=True)
st.markdown("---")

# helpers
def extract_text(path, ftype):
    if ftype == "txt":
        return open(path, "r", encoding="utf-8").read()
    if ftype == "csv":
        return pd.read_csv(path).to_string()
    if ftype == "docx" and docx:
        doc = docx.Document(path)
        return "\n".join(p.text for p in doc.paragraphs)
    if ftype == "pptx" and pptx:
        prs = pptx.Presentation(path)
        return "\n".join(
            shp.text for sl in prs.slides for shp in sl.shapes if hasattr(shp, "text")
        )
    return ""

def display_contexts(ctxs):
    st.markdown("### ğŸ” Retrieved Contexts")
    for i, c in enumerate(ctxs, 1):
        st.markdown(f"- **Context {i}:** {c}")

# indexing & chat
if uploaded_file:
    os.makedirs("docs", exist_ok=True)
    save_path = os.path.join("docs", uploaded_file.name)
    with open(save_path, "wb") as f:
        f.write(uploaded_file.getbuffer())
    ext = uploaded_file.name.rsplit(".", 1)[1].lower()

    @st.cache_resource
    def load_idx(p): return build_or_load_index(p)

    if ext in ["txt", "csv", "docx", "pptx"]:
        raw = extract_text(save_path, ext)
        txt_path = save_path + ".txt"
        with open(txt_path, "w", encoding="utf-8") as tf: tf.write(raw)
        idx_path = txt_path
    else:
        idx_path = save_path

    embedder, texts, index = load_idx(idx_path)
    st.session_state.setdefault("chat_history", [])

    # replay
    for m in st.session_state.chat_history:
        role = "user" if isinstance(m, HumanMessage) else "assistant"
        with st.chat_message(role):
            st.markdown(m.content)

    # new input
    if q := st.chat_input("ğŸ’¬ Ask something..."):
        st.session_state.chat_history.append(HumanMessage(content=q))
        with st.chat_message("user"):
            st.markdown(q)

        ctxs = query_faiss_index(q, embedder, index, texts)
        if show_context: display_contexts(ctxs)

        resp = get_llm_response(
            api_key=GROQ_API_KEY,
            query=q,
            contexts=ctxs,
            chat_history=st.session_state.chat_history
        )
        st.session_state.chat_history.append(AIMessage(content=resp))
        with st.chat_message("assistant"):
            st.markdown(resp)

    # download button
    if st.session_state.chat_history:
        pdf_bytes = make_pdf_bytes(st.session_state.chat_history)
        st.sidebar.download_button(
            "ğŸ“¥ Download Chat as PDF",
            data=pdf_bytes,
            file_name="chat_report.pdf",
            mime="application/pdf"
        )
else:
    st.info("ğŸ“‚ Upload a document to begin.")
